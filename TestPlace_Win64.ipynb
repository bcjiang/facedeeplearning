{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import skimage\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import ORB\n",
    "import match_orb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1_raw = cv2.imread('hopkins1.jpg')\n",
    "img2_raw = cv2.imread('hopkins2.jpg')\n",
    "\n",
    "img1 = cv2.cvtColor(img1_raw, cv2.COLOR_RGB2GRAY)\n",
    "img2 = cv2.cvtColor(img2_raw, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "detector_extractor1 = ORB(n_keypoints=500)\n",
    "detector_extractor2 = ORB(n_keypoints=500)\n",
    "\n",
    "detector_extractor1.detect_and_extract(img1)\n",
    "detector_extractor2.detect_and_extract(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displaying_matches(image1, image2, feature_coords1, feature_coords2, matches):\n",
    "    if image1.shape[0] == image2.shape[0]:\n",
    "        SbS = np.concatenate((image1,image2), axis=1)\n",
    "    elif image1.shape[0] > image2.shape[0]:\n",
    "        image2_extended = cv2.copyMakeBorder(image2,0,image1.shape[0]-image2.shape[0],0,0,cv2.BORDER_CONSTANT)\n",
    "        SbS = np.concatenate((image1,image2_extended), axis=1)\n",
    "    else:\n",
    "        image1_extended = cv2.copyMakeBorder(image1,0,image2.shape[0]-image1.shape[0],0,0,cv2.BORDER_CONSTANT)\n",
    "        SbS = np.concatenate((image1_extended,image2), axis=1)\n",
    "    img1_width = image1.shape[1]\n",
    "    color = np.array([255,0,0])\n",
    "    for i in range(len(matches)):\n",
    "        cv2.line(SbS, (int(feature_coords1[matches[i][0]][1]), int(feature_coords1[matches[i][0]][0])), \\\n",
    "            (int(feature_coords2[matches[i][1]][1])+img1_width, int(feature_coords2[matches[i][1]][0])), color)\n",
    "    for k in range(len(feature_coords1)):\n",
    "        SbS[int(feature_coords1[k][0]), int(feature_coords1[k][1])] = color\n",
    "    for k in range(len(feature_coords2)):\n",
    "        SbS[int(feature_coords2[k][0]), int(feature_coords2[k][1])+img1_width] = color\n",
    "    cv2.namedWindow(\"match features in two images\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('match features in two images', SbS)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    return SbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_orb() started.\n",
      "match_orb() finished. Running time:  55.1610000134\n"
     ]
    }
   ],
   "source": [
    "reload(match_orb)\n",
    "matches = match_orb.match_orb(detector_extractor1.descriptors, detector_extractor2.descriptors)\n",
    "SbS = displaying_matches(img1_raw, img2_raw, detector_extractor1.keypoints, detector_extractor2.keypoints, matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_proj_xform(matches,features1,features2,image1,image2,iter_rounds = 100):\n",
    "\n",
    "    print \"compute_proj_xform() started.\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    proj_xform = np.zeros((3,3))\n",
    "    height, width = image1.shape[0:2]\n",
    "    image_raw1 = np.copy(image1)\n",
    "    image_raw2 = np.copy(image2)\n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2GRAY)\n",
    "    image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # RANSAC select points for computing xform\n",
    "    best_xform = np.zeros((3,3))\n",
    "    best_xform[2,2] = 1\n",
    "    best_inlier_std = float('Inf')\n",
    "    best_inlier_count = 0\n",
    "    best_inlier_index = []\n",
    "    inlier_thresh = 5\n",
    "    curr_xform = np.zeros((3,3))\n",
    "\n",
    "    for i in range(iter_rounds):\n",
    "        inliers_count = 0\n",
    "        inliers_dist = []\n",
    "        inliers_index = []\n",
    "\n",
    "        # Randomly choose 4 matches\n",
    "        rand_match_index = np.random.choice(range(len(matches)),4)\n",
    "        rand_match = []\n",
    "        for k in range(4):\n",
    "            rand_match.append(matches[rand_match_index[k]])\n",
    "\n",
    "        # Check whether they are good points: not too close, not colinear\n",
    "        x1a = features1[rand_match[0][0]][1]\n",
    "        y1a = features1[rand_match[0][0]][0]\n",
    "        x2a = features1[rand_match[1][0]][1]\n",
    "        y2a = features1[rand_match[1][0]][0]\n",
    "        x3a = features1[rand_match[2][0]][1]\n",
    "        y3a = features1[rand_match[2][0]][0]\n",
    "        x4a = features1[rand_match[3][0]][1]\n",
    "        y4a = features1[rand_match[3][0]][0]\n",
    "        x_mean = np.mean([x1a,x2a,x3a,x4a])\n",
    "        y_mean = np.mean([y1a,y2a,y3a,y4a])\n",
    "        xyz1 = np.array([[x1a-x_mean,y1a-y_mean,1],[x2a-x_mean,y2a-y_mean,1],[x3a-x_mean,y3a-y_mean,1]])\n",
    "        xyz2 = np.array([[x4a-x_mean,y4a-y_mean,1],[x2a-x_mean,y2a-y_mean,1],[x3a-x_mean,y3a-y_mean,1]])\n",
    "        xyz3 = np.array([[x1a-x_mean,y1a-y_mean,1],[x4a-x_mean,y4a-y_mean,1],[x3a-x_mean,y3a-y_mean,1]])\n",
    "        xyz4 = np.array([[x1a-x_mean,y1a-y_mean,1],[x2a-x_mean,y2a-y_mean,1],[x4a-x_mean,y4a-y_mean,1]])\n",
    "        if np.absolute(np.linalg.det(xyz1)) < 100 or np.absolute(np.linalg.det(xyz2)) < 100 or \\\n",
    "            np.absolute(np.linalg.det(xyz3)) < 100 or np.absolute(np.linalg.det(xyz4)) < 100:\n",
    "                continue\n",
    "        x1b = features2[rand_match[0][1]][1]\n",
    "        y1b = features2[rand_match[0][1]][0]\n",
    "        x2b = features2[rand_match[1][1]][1]\n",
    "        y2b = features2[rand_match[1][1]][0]\n",
    "        x3b = features2[rand_match[2][1]][1]\n",
    "        y3b = features2[rand_match[2][1]][0]\n",
    "        x4b = features2[rand_match[3][1]][1]\n",
    "        y4b = features2[rand_match[3][1]][0]\n",
    "        x_mean = np.mean([x1b,x2b,x3b,x4b])\n",
    "        y_mean = np.mean([y1b,y2b,y3b,y4b])\n",
    "        xyz1 = np.array([[x1b-x_mean,y1b-y_mean,1],[x2b-x_mean,y2b-y_mean,1],[x3b-x_mean,y3b-y_mean,1]])\n",
    "        xyz2 = np.array([[x4b-x_mean,y4b-y_mean,1],[x2b-x_mean,y2b-y_mean,1],[x3b-x_mean,y3b-y_mean,1]])\n",
    "        xyz3 = np.array([[x1b-x_mean,y1b-y_mean,1],[x4b-x_mean,y4b-y_mean,1],[x3b-x_mean,y3b-y_mean,1]])\n",
    "        xyz4 = np.array([[x1b-x_mean,y1b-y_mean,1],[x2b-x_mean,y2b-y_mean,1],[x4b-x_mean,y4b-y_mean,1]])\n",
    "        if np.absolute(np.linalg.det(xyz1)) < 100 or np.absolute(np.linalg.det(xyz2)) < 100 or \\\n",
    "            np.absolute(np.linalg.det(xyz3)) < 100 or np.absolute(np.linalg.det(xyz4)) < 100:\n",
    "                continue\n",
    "\n",
    "        # Compute curr_xform based on the 3 points chosen\n",
    "        A = np.array([[x1a,y1a,1,0,0,0,-x1b*x1a,-x1b*y1a,-x1b],\\\n",
    "            [0,0,0,x1a,y1a,1,-y1b*x1a,-y1b*y1a,-y1b],\\\n",
    "            [x2a,y2a,1,0,0,0,-x2b*x2a,-x2b*y2a,-x2b],\\\n",
    "            [0,0,0,x2a,y2a,1,-y2b*x2a,-y2b*y2a,-y2b],\\\n",
    "            [x3a,y3a,1,0,0,0,-x3b*x3a,-x3b*y3a,-x3b],\\\n",
    "            [0,0,0,x3a,y3a,1,-y3b*x3a,-y3b*y3a,-y3b],\\\n",
    "            [x4a,y4a,1,0,0,0,-x4b*x4a,-x4b*y4a,-x4b],\\\n",
    "            [0,0,0,x4a,y4a,1,-y4b*x4a,-y4b*y4a,-y4b]]);\n",
    "        AT = np.transpose(A)\n",
    "        ATA = np.dot(AT,A)\n",
    "        U,D,UT = np.linalg.svd(ATA)\n",
    "        curr_xform = np.reshape(U[:,8],(3,3))\n",
    "\n",
    "        # Calculate the distance for each feature under curr_xform and count inliers\n",
    "        for j in range(len(matches)):\n",
    "            pt1 = np.array([[features1[matches[j][0]][1]],[features1[matches[j][0]][0]],[1]])\n",
    "            pt2 = np.array([[features2[matches[j][1]][1]],[features2[matches[j][1]][0]],[1]])\n",
    "            pt1_xform = np.dot(curr_xform,pt1)/(curr_xform[2,0]*pt1[0]+curr_xform[2,1]*pt1[1]+curr_xform[2,2])\n",
    "            dist = np.sqrt((pt1_xform[0]-pt2[0])**2 + (pt1_xform[1]-pt2[1])**2)\n",
    "            if dist < inlier_thresh:\n",
    "                inliers_count = inliers_count + 1\n",
    "                inliers_dist.append(dist)\n",
    "                inliers_index.append(j)\n",
    "\n",
    "        # Update the best transform\n",
    "        if inliers_count > best_inlier_count:\n",
    "            best_inlier_count = inliers_count\n",
    "            best_xform = np.copy(curr_xform)\n",
    "            best_inlier_index = inliers_index\n",
    "        else:\n",
    "            if inliers_count == best_inlier_count and np.std(inliers_dist) < best_inlier_std:\n",
    "                best_inlier_std = np.std(inliers_dist)\n",
    "                best_xform = np.copy(curr_xform)\n",
    "                best_inlier_index = inliers_index\n",
    "\n",
    "    print \"found good matching pairs:\", best_inlier_count\n",
    "    # Show the RANSAC works\n",
    "    if image_raw1.shape[0] == image_raw2.shape[0]:\n",
    "        SbS = np.concatenate((image_raw1,image_raw2), axis=1)\n",
    "    elif image_raw1.shape[0] > image_raw2.shape[0]:\n",
    "        image2_extended = cv2.copyMakeBorder(image_raw2,0,image_raw1.shape[0]-image_raw2.shape[0],0,0,cv2.BORDER_CONSTANT)\n",
    "        SbS = np.concatenate((image_raw1,image2_extended), axis=1)\n",
    "    else:\n",
    "        image1_extended = cv2.copyMakeBorder(image_raw1,0,image_raw2.shape[0]-image_raw1.shape[0],0,0,cv2.BORDER_CONSTANT)\n",
    "        SbS = np.concatenate((image1_extended,image_raw2), axis=1)\n",
    "    color_outlier = np.array([0,0,255])\n",
    "    color_inlier = np.array([0,255,0])\n",
    "    for i in range(len(matches)):\n",
    "        if i in best_inlier_index:\n",
    "            cv2.line(SbS, (int(features1[matches[i][0]][1]), int(features1[matches[i][0]][0])), \\\n",
    "                     (int(features2[matches[i][1]][1])+width, int(features2[matches[i][1]][0])), color_inlier)\n",
    "        else:\n",
    "            cv2.line(SbS, (int(features1[matches[i][0]][1]), int(features1[matches[i][0]][0])), \\\n",
    "                     (int(features2[matches[i][1]][1])+width, int(features2[matches[i][1]][0])), color_outlier)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    cv2.namedWindow(\"RANSAC\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('RANSAC', SbS)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    proj_xform = best_xform\n",
    "\n",
    "    print \"compute_proj_xform() finished. Running time: \", elapsed_time\n",
    "\n",
    "    return proj_xform, best_inlier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_proj_xform() started.\n",
      "found good matching pairs: 28\n",
      "compute_proj_xform() finished. Running time:  11.0080001354\n"
     ]
    }
   ],
   "source": [
    "proj_xform, ransac_inliers = compute_proj_xform(matches,detector_extractor1.keypoints,detector_extractor2.keypoints,img1_raw,img2_raw,iter_rounds = 500)\n",
    "# img1_raw, img2_raw, detector_extractor1.keypoints, detector_extractor2.keypoints, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "good_matches = []\n",
    "for i in range(len(matches)):\n",
    "        if i in ransac_inliers:\n",
    "            good_matches.append(matches[i])\n",
    "print len(good_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[154, 87], [466, 103], [62, 148], [195, 164], [102, 172], [233, 176], [408, 199], [152, 206], [156, 236], [207, 241], [112, 269], [108, 287], [400, 294], [141, 310], [490, 316], [149, 319], [360, 320], [413, 328], [276, 347], [312, 350], [179, 371], [192, 393], [495, 397], [328, 414], [243, 420], [460, 444], [345, 480], [242, 485]]\n"
     ]
    }
   ],
   "source": [
    "print good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_fundamental(features1, features2, matches):\n",
    "    if len(matches) < 9:\n",
    "        print \"Not enough matches to compute fundamental matrix!\"\n",
    "        return np.zeros([3,3])\n",
    "    else:\n",
    "        A = np.ones([len(matches),9])\n",
    "        for i in range(len(matches)):\n",
    "            ul = int(features1[matches[i][0]][1])\n",
    "            vl = int(features1[matches[i][0]][0])\n",
    "            ur = int(features2[matches[i][1]][1])\n",
    "            vr = int(features2[matches[i][1]][0])\n",
    "            A[i,0] = ul*ur\n",
    "            A[i,1] = ul*vr\n",
    "            A[i,2] = ul\n",
    "            A[i,3] = vl*ur\n",
    "            A[i,4] = vl*vr\n",
    "            A[i,5] = vl\n",
    "            A[i,6] = ur\n",
    "            A[i,7] = vr\n",
    "        AT = np.transpose(A)\n",
    "        ATA = np.dot(AT,A)\n",
    "        U,D,UT = np.linalg.svd(ATA)\n",
    "        fundamental = np.reshape(U[:,8],(3,3))\n",
    "        for i in range(len(matches)):\n",
    "            left_coords = np.array([int(features1[matches[i][0]][1]),int(features1[matches[i][0]][0]),1])\n",
    "            right_coords = np.array([int(features2[matches[i][1]][1]),int(features2[matches[i][1]][0]),1])\n",
    "            res = np.dot(np.dot(left_coords, fundamental), right_coords)\n",
    "            print \"residual: \", res\n",
    "        return fundamental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual:  0.000116928656694\n",
      "residual:  7.68860096855e-05\n",
      "residual:  -0.000988336057641\n",
      "residual:  -0.000277909685233\n",
      "residual:  0.000489186288813\n",
      "residual:  -0.000565976940844\n",
      "residual:  0.000180742711634\n",
      "residual:  -0.000315209260202\n",
      "residual:  0.0001537320032\n",
      "residual:  -0.000176755006334\n",
      "residual:  -0.000429955075229\n",
      "residual:  0.000589257935578\n",
      "residual:  -8.72962098324e-05\n",
      "residual:  2.1641266995e-05\n",
      "residual:  -0.000169237374815\n",
      "residual:  -0.000377964093125\n",
      "residual:  6.16412512921e-05\n",
      "residual:  -0.00032705959042\n",
      "residual:  0.00029835706475\n",
      "residual:  0.000536391180781\n",
      "residual:  0.000397808240845\n",
      "residual:  0.000430574758811\n",
      "residual:  -0.000450667532878\n",
      "residual:  -0.000148125518475\n",
      "residual:  0.00042047587245\n",
      "residual:  0.000243736126492\n",
      "residual:  0.00122072483647\n",
      "residual:  -0.000917435908967\n",
      "[[  2.37594412e-07   1.21793584e-05  -3.56497365e-03]\n",
      " [ -1.01239041e-05  -2.02154158e-08   1.34337856e-03]\n",
      " [  2.75604900e-03  -4.70232974e-03   9.99977889e-01]]\n"
     ]
    }
   ],
   "source": [
    "F = compute_fundamental(detector_extractor1.keypoints, detector_extractor2.keypoints, good_matches)\n",
    "print F\n",
    "# F2 = compute_fundamental(detector_extractor1.keypoints, detector_extractor2.keypoints, good_matches[0:20])\n",
    "# print F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_epipolar(F, img1, img2, features1, features2, matches, num_points = 2):\n",
    "    # num_point should not be larger than 5\n",
    "    height, width = img1.shape[0:2]\n",
    "    if img1.shape[0] == img2.shape[0]:\n",
    "        SbS = np.concatenate((img1,img2), axis=1)\n",
    "    elif img1.shape[0] > img2.shape[0]:\n",
    "        image2_extended = cv2.copyMakeBorder(img2,0,img1.shape[0]-img2.shape[0],0,0,cv2.BORDER_CONSTANT)\n",
    "        SbS = np.concatenate((img1,image2_extended), axis=1)\n",
    "    else:\n",
    "        image1_extended = cv2.copyMakeBorder(img1,0,img2.shape[0]-img1.shape[0],0,0,cv2.BORDER_CONSTANT)\n",
    "        SbS = np.concatenate((image1_extended,img2), axis=1)\n",
    "    \n",
    "    color_change = 0\n",
    "    match_sample = random.sample(matches, num_points)\n",
    "    for i in range(num_points):\n",
    "        match = match_sample[i]\n",
    "        left_coords = np.array([int(features1[match[0]][1]),int(features1[match[0]][0]),1])\n",
    "        right_coords = np.array([int(features2[match[1]][1]),int(features2[match[1]][0]),1])\n",
    "        cv2.circle(SbS, (left_coords[0], left_coords[1]), 10, np.array([color_change,255-color_change,color_change]), 2)\n",
    "        cv2.circle(SbS, (right_coords[0]+width, right_coords[1]), 10, np.array([color_change,255-color_change,color_change]), 2)\n",
    "        print left_coords\n",
    "        print right_coords\n",
    "        print F\n",
    "        params = np.dot(left_coords, F)\n",
    "        print params\n",
    "        error = np.dot(params, right_coords)\n",
    "        print \"LSQ error:\", error\n",
    "        line_ends = []\n",
    "        if -params[2]/params[1] >= 0 and -params[2]/params[1] <= height:\n",
    "            line_ends.append([0, int(-params[2]/params[1])])\n",
    "        if -(params[0]*width+params[2])/params[1] >= 0 and -(params[0]*width+params[2])/params[1] <= height:\n",
    "            line_ends.append([width, int(-(params[0]*width+params[2])/params[1])])\n",
    "        if -params[2]/params[0] >= 0 and -params[2]/params[0] <= width:\n",
    "            line_ends.append([int(-params[2]/params[0]), 0])\n",
    "        if -(params[1]*height+params[2])/params[0] >= 0 and -(params[1]*height+params[2])/params[0] <= width:\n",
    "            line_ends.append([int(-(params[1]*height+params[2])/params[0]), height])\n",
    "        if len(line_ends) == 2:\n",
    "            print \"line_ends:\", line_ends\n",
    "            cv2.line(SbS, (line_ends[0][0]+width,line_ends[0][1]), (line_ends[1][0]+width, line_ends[1][1]), np.array([color_change,255-color_change,color_change]), 2)\n",
    "        color_change += 50\n",
    "        \n",
    "    cv2.namedWindow(\"Epipolar\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Epipolar', SbS)\n",
    "    cv2.waitKey(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[383 312   1]\n",
      "[128 319   1]\n",
      "[[  2.37594412e-07   1.21793584e-05  -3.56497365e-03]\n",
      " [ -1.01239041e-05  -2.02154158e-08   1.34337856e-03]\n",
      " [  2.75604900e-03  -4.70232974e-03   9.99977889e-01]]\n",
      "[ -3.11610421e-04  -4.39426727e-05   5.37270914e-02]\n",
      "LSQ error: -0.000176755006334\n",
      "line_ends: [[172, 0], [64, 768L]]\n",
      "[381 311   1]\n",
      "[126 319   1]\n",
      "[[  2.37594412e-07   1.21793584e-05  -3.56497365e-03]\n",
      " [ -1.01239041e-05  -2.02154158e-08   1.34337856e-03]\n",
      " [  2.75604900e-03  -4.70232974e-03   9.99977889e-01]]\n",
      "[ -3.01961705e-04  -6.82811741e-05   5.95136602e-02]\n",
      "LSQ error: -0.000315209260202\n",
      "line_ends: [[197, 0], [23, 768L]]\n",
      "[373 174   1]\n",
      "[117 187   1]\n",
      "[[  2.37594412e-07   1.21793584e-05  -3.56497365e-03]\n",
      " [ -1.01239041e-05  -2.02154158e-08   1.34337856e-03]\n",
      " [  2.75604900e-03  -4.70232974e-03   9.99977889e-01]]\n",
      "[ 0.00108311 -0.00016295 -0.09600941]\n",
      "LSQ error: 0.000243736126492\n",
      "line_ends: [[88, 0], [204, 768L]]\n",
      "[363 231   1]\n",
      "[105 242   1]\n",
      "[[  2.37594412e-07   1.21793584e-05  -3.56497365e-03]\n",
      " [ -1.01239041e-05  -2.02154158e-08   1.34337856e-03]\n",
      " [  2.75604900e-03  -4.70232974e-03   9.99977889e-01]]\n",
      "[ 0.00050367 -0.00028589  0.0162129 ]\n",
      "LSQ error: -8.72962098324e-05\n",
      "line_ends: [[0, 56], [403, 768L]]\n"
     ]
    }
   ],
   "source": [
    "draw_epipolar(F, img1_raw, img2_raw, detector_extractor1.keypoints, detector_extractor2.keypoints, good_matches, 4)\n",
    "# img1_raw, img2_raw, detector_extractor1.keypoints, detector_extractor2.keypoints, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.85023830e-06   3.85413147e-06  -2.88401156e-03]\n",
      " [ -1.97791500e-07  -5.61057548e-07   3.08822606e-04]\n",
      " [ -1.02287227e-03  -1.29788964e-03   9.99994428e-01]]\n"
     ]
    }
   ],
   "source": [
    "print F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1]\n"
     ]
    }
   ],
   "source": [
    "aaa = [1,2,3,4]\n",
    "bbb = random.sample(aaa,2)\n",
    "print bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]] [16 20 24]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,1])\n",
    "Te = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print Te, np.dot(x, Te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997776871089\n"
     ]
    }
   ],
   "source": [
    "print -7.32775991e-04 -1.48506292e-03 +9.99994710e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "b = [11,23,33,44]\n",
    "total = [a,b]\n",
    "with open(\"testsave.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(total, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [11, 23, 33, 44]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"testsave.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 250)\n"
     ]
    }
   ],
   "source": [
    "img1 = Image.open(\"./facedeeplearning/lfw/Abdullah/Abdullah_0001.jpg\")\n",
    "\n",
    "translate_x = int(10 - random.random()*20)\n",
    "translate_y = int(10 - random.random()*20)\n",
    "img1 = img1.transform(img1.size, Image.AFFINE, (1,0,translate_x,0,1,translate_y))\n",
    "img1.save('test23.bmp')\n",
    "\n",
    "# angle = 30 - random.random()*60\n",
    "# img1 = img1.rotate(angle)\n",
    "# img1.show()\n",
    "\n",
    "# img1 = img1.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "# ratio = 0.6*random.random() + 0.7\n",
    "# if ratio > 1:\n",
    "#     old_size = img1.size\n",
    "#     new_size = tuple([int(i*ratio) for i in img1.size])\n",
    "#     img1 = img1.resize(new_size, Image.ANTIALIAS)\n",
    "#     left = abs((old_size[0] - new_size[0])/2)\n",
    "#     top = abs((old_size[1] - new_size[1])/2)\n",
    "#     right = abs((old_size[0] + new_size[0])/2)\n",
    "#     bottom = abs((old_size[1] + new_size[1])/2)\n",
    "#     img1 = img1.crop((left,top,right,bottom))\n",
    "# else:\n",
    "#     old_size = img1.size\n",
    "#     new_size = tuple([int(i*ratio) for i in img1.size])\n",
    "#     img1 = img1.resize(new_size, Image.ANTIALIAS)\n",
    "#     left = 0\n",
    "#     top = 0\n",
    "#     right = old_size[0]\n",
    "#     bottom = old_size[1]\n",
    "#     img1 = img1.crop((left,top,right,bottom))\n",
    "\n",
    "\n",
    "print img1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-ed7c0a5ac229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# print tuple([i*1.2 for i in img1.size]) - (250, 250)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;31m# img1.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# print tuple([i*1.2 for i in img1.size]) - (250, 250)\n",
    "print img1.size\n",
    "# img1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displaying_matches(image1, image2, feature_coords1, feature_coords2, matches):\n",
    "    if image1.shape[0] == image2.shape[0]:\n",
    "        SbS = np.concatenate((image1,image2), axis=1)\n",
    "    elif image1.shape[0] > image2.shape[0]:\n",
    "        image2_extended = cv2.copyMakeBorder(image2,0,image1.shape[0]-image2.shape[0],0,0,cv2.BORDER_CONSTANT)\n",
    "        SbS = np.concatenate((image1,image2_extended), axis=1)\n",
    "    else:\n",
    "        image1_extended = cv2.copyMakeBorder(image1,0,image2.shape[0]-image1.shape[0],0,0,cv2.BORDER_CONSTANT)\n",
    "        SbS = np.concatenate((image1_extended,image2), axis=1)\n",
    "    img1_width = image1.shape[1]\n",
    "    color = np.array([255,0,0])\n",
    "    for i in range(len(matches)):\n",
    "        cv2.line(SbS, (int(feature_coords1[matches[i][0]][1]), int(feature_coords1[matches[i][0]][0])), \\\n",
    "            (int(feature_coords2[matches[i][1]][1])+img1_width, int(feature_coords2[matches[i][1]][0])), color)\n",
    "    for k in range(len(feature_coords1)):\n",
    "        SbS[int(feature_coords1[k][0]), int(feature_coords1[k][1])] = color\n",
    "    for k in range(len(feature_coords2)):\n",
    "        SbS[int(feature_coords2[k][0]), int(feature_coords2[k][1])+img1_width] = color\n",
    "    cv2.namedWindow(\"match features in two images\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('match features in two images', SbS)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    return SbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1_raw = cv2.imread('hopkins1.JPG')\n",
    "img2_raw = cv2.imread('hopkins2.JPG')\n",
    "img1 = cv2.cvtColor(img1_raw, cv2.COLOR_RGB2GRAY)\n",
    "img2 = cv2.cvtColor(img2_raw, cv2.COLOR_RGB2GRAY)\n",
    "detector_extractor1 = ORB(n_keypoints=300)\n",
    "detector_extractor2 = ORB(n_keypoints=300)\n",
    "detector_extractor1.detect_and_extract(img1)\n",
    "detector_extractor2.detect_and_extract(img2)\n",
    "# matches = match_descriptors(detector_extractor1.descriptors, detector_extractor2.descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches1 = match_descriptors(detector_extractor1.descriptors, detector_extractor2.descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_orb() started.\n",
      "match_orb() finished. Running time:  21.5709998608\n"
     ]
    }
   ],
   "source": [
    "reload(match_orb)\n",
    "matches2 = match_orb.match_orb(detector_extractor1.descriptors, detector_extractor2.descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401, 4], [693, 7], [608, 11], [262, 18], [518, 22], [698, 30], [221, 33], [712, 39], [213, 44], [864, 46], [506, 53], [923, 57], [834, 58], [730, 59], [313, 61], [417, 62], [43, 64], [458, 65], [520, 69], [299, 70], [804, 75], [533, 79], [87, 80], [154, 87], [78, 90], [329, 95], [392, 96], [979, 101], [579, 106], [4, 107], [318, 111], [703, 124], [187, 131], [416, 132], [67, 134], [398, 143], [330, 146], [62, 148], [308, 153], [794, 155], [36, 158], [838, 161], [195, 164], [101, 170], [536, 171], [102, 172], [233, 176], [374, 178], [138, 183], [790, 185], [813, 186], [219, 188], [377, 195], [293, 196], [839, 197], [408, 199], [912, 201], [83, 203], [232, 205], [152, 206], [225, 208], [126, 221], [547, 224], [103, 226], [862, 228], [18, 230], [801, 235], [156, 236], [207, 241], [987, 242], [405, 243], [274, 246], [566, 248], [723, 251], [614, 254], [473, 259], [756, 260], [954, 264], [112, 269], [123, 276], [502, 278], [647, 285], [108, 287], [358, 290], [174, 291], [205, 293], [400, 294], [226, 296], [399, 301], [925, 306], [675, 307], [141, 310], [372, 314], [931, 315], [490, 316], [248, 317], [131, 318], [149, 319], [360, 320], [705, 325], [254, 327], [413, 328], [155, 334], [565, 339], [77, 341], [107, 343], [276, 347], [559, 349], [312, 350], [144, 356], [498, 362], [425, 363], [179, 371], [516, 372], [627, 375], [622, 376], [423, 377], [619, 378], [553, 386], [86, 390], [192, 393], [495, 397], [139, 399], [722, 403], [595, 404], [930, 406], [280, 412], [328, 414], [451, 415], [680, 416], [767, 417], [951, 423], [302, 426], [685, 427], [305, 431], [183, 436], [288, 439], [127, 442], [460, 444], [727, 446], [775, 450], [121, 455], [825, 457], [217, 464], [457, 467], [143, 468], [382, 475], [345, 480], [899, 484], [242, 485], [433, 487], [388, 506], [733, 507], [151, 510], [426, 515], [153, 517], [766, 521], [700, 527], [199, 532], [997, 535], [250, 538], [601, 539], [362, 540], [270, 544], [792, 548], [527, 550], [990, 552], [231, 559], [412, 561], [415, 565], [782, 569], [504, 570], [354, 571], [389, 573], [569, 578], [114, 580], [443, 586], [929, 590], [321, 600], [272, 603], [941, 605], [924, 607], [833, 611], [546, 614], [216, 624], [158, 631], [371, 632], [501, 638], [140, 639], [3, 641], [575, 644], [642, 648], [297, 650], [365, 655], [249, 656], [677, 661], [464, 663], [592, 668], [252, 670], [373, 673], [203, 676], [958, 677], [10, 678], [724, 682], [548, 689], [315, 690], [376, 695], [357, 698], [902, 699], [150, 708], [317, 711], [341, 713], [996, 714], [137, 715], [886, 718], [296, 721], [549, 724], [496, 729], [842, 730], [346, 731], [212, 732], [754, 734], [576, 737], [59, 738], [331, 740], [772, 755], [664, 759], [531, 764], [637, 766], [918, 768], [607, 769], [503, 771], [820, 774], [751, 777], [275, 780], [784, 783], [364, 785], [5, 789], [265, 800], [965, 801], [42, 802], [257, 803], [0, 804], [84, 810], [817, 815], [709, 821], [988, 825], [593, 830], [52, 831], [706, 837], [290, 848], [636, 859], [970, 860], [760, 862], [738, 863], [507, 865], [860, 867], [893, 873], [419, 876], [208, 879], [892, 880], [390, 882], [211, 885], [129, 888], [535, 892], [488, 901], [846, 904], [511, 905], [901, 907], [370, 908], [752, 909], [582, 911], [773, 915], [224, 926], [656, 927], [910, 931], [116, 937], [277, 940], [650, 945], [687, 947], [482, 954], [947, 955], [891, 965], [726, 967], [651, 970], [210, 972], [513, 974], [904, 975], [872, 976], [873, 978], [835, 999]]\n"
     ]
    }
   ],
   "source": [
    "print matches2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "print sum([i**2 for i in [int(m)-int(n) for m,n in zip(detector_extractor1.descriptors[1],detector_extractor2.descriptors[1])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[40, 65, 75],\n",
       "        [40, 65, 75],\n",
       "        [41, 66, 76],\n",
       "        ..., \n",
       "        [18, 27, 30],\n",
       "        [15, 27, 29],\n",
       "        [14, 26, 28]],\n",
       "\n",
       "       [[39, 65, 77],\n",
       "        [39, 65, 77],\n",
       "        [40, 66, 78],\n",
       "        ..., \n",
       "        [17, 26, 29],\n",
       "        [14, 26, 28],\n",
       "        [13, 25, 27]],\n",
       "\n",
       "       [[38, 66, 77],\n",
       "        [40, 66, 78],\n",
       "        [41, 67, 79],\n",
       "        ..., \n",
       "        [16, 25, 28],\n",
       "        [14, 26, 28],\n",
       "        [13, 25, 27]],\n",
       "\n",
       "       ..., \n",
       "       [[15, 26, 30],\n",
       "        [15, 26, 30],\n",
       "        [16, 27, 31],\n",
       "        ..., \n",
       "        [ 4,  7,  5],\n",
       "        [ 4,  7,  5],\n",
       "        [ 4,  7,  5]],\n",
       "\n",
       "       [[18, 29, 33],\n",
       "        [17, 28, 32],\n",
       "        [17, 28, 32],\n",
       "        ..., \n",
       "        [ 6,  9,  7],\n",
       "        [ 6,  9,  7],\n",
       "        [ 3,  8,  6]],\n",
       "\n",
       "       [[19, 30, 34],\n",
       "        [19, 30, 34],\n",
       "        [18, 29, 33],\n",
       "        ..., \n",
       "        [ 7, 10,  8],\n",
       "        [ 6,  9,  7],\n",
       "        [ 4,  9,  7]]], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displaying_matches(img1_raw, img2_raw, detector_extractor1.keypoints, detector_extractor2.keypoints, matches1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1 = np.zeros((100, 100))\n",
    "img2 = np.zeros_like(img1)\n",
    "np.random.seed(1)\n",
    "square = np.random.rand(20, 20)\n",
    "img1[40:60, 40:60] = square\n",
    "img2[53:73, 53:73] = square\n",
    "detector_extractor1 = ORB(n_keypoints=10)\n",
    "detector_extractor2 = ORB(n_keypoints=10)\n",
    "detector_extractor1.detect_and_extract(img1)\n",
    "detector_extractor2.detect_and_extract(img2)\n",
    "matches = match_descriptors(detector_extractor1.descriptors,detector_extractor2.descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displaying_matches(img1, img2, detector_extractor1.keypoints, detector_extractor2.keypoints, matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = 2 \n",
    "if a>1:\n",
    "    print \"1\"\n",
    "elif a>1.2:\n",
    "    print \"2\"\n",
    "else:\n",
    "    print \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = []\n",
    "with open(\"test.txt\") as f:\n",
    "    content = f.readlines()\n",
    "content = [x.split() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Richard_Gere/Richard_Gere_0006.jpg', 'Richard_Gere/Richard_Gere_0010.jpg', '1']\n"
     ]
    }
   ],
   "source": [
    "print content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\lfw\\Richard_Gere/Richard_Gere_0006.jpg\n"
     ]
    }
   ],
   "source": [
    "root_dir = '.\\lfw'\n",
    "imgpath = os.path.join(root_dir,content[0][0])\n",
    "print imgpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testimg = cv2.imread(imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('test',testimg)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250L, 250L, 3L)\n"
     ]
    }
   ],
   "source": [
    "print testimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
